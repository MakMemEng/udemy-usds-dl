{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ab236d-0a06-48f0-8c80-3101b385b300",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec2a018-e8b9-4a3a-92ea-782c03e97980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff682e86-3e83-4599-ba8c-38fbc4dfce4a",
   "metadata": {},
   "source": [
    "### Bakwardをスクラッチで実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6180124-bf1e-4a49-8bcb-66b80b77c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(A, W, b, Z):\n",
    "    W.grad_ = Z.grad_.T @ A\n",
    "    b.grad_ = torch.sum(Z.grad_, dim=0) # バイアス項は全てのデータに加算される形になるので，逆伝播時には集約する\n",
    "    A.grad_ = Z.grad_ @ W\n",
    "    \n",
    "def relu_backward(Z, A):\n",
    "    # 入力が正なら1(True)として，負なら0(False), それぞれの要素をマスクする\n",
    "    Z.grad_ = A.grad_ * (Z>0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4440b666-c2f7-4927-a08b-33a38b2e3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmaxとcrossentropyを同じ関数にする（する必要はないが，pytorchの実装に合わせている\n",
    "def softmax_cross_entropy(x, y_true):\n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    softmax_out =  e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "    loss = -torch.sum(y_true * torch.log(softmax_out + 1e-10)) / y_true.shape[0]\n",
    "    return loss, softmax_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bdea0e8-6c88-45cc-ab77-5cab2bb16340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(X, W, b):\n",
    "    return X@W.T + b\n",
    "def relu(Z):\n",
    "    return Z.clamp_min(0.)\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    loss, A2 = softmax_cross_entropy(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = (A2 - y) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dfafe-8f1b-437b-8964-44676aae3802",
   "metadata": {},
   "source": [
    "### Autogradの結果と一致することを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537c4490-867b-4f29-b42e-59d455a21038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 8, 8) (1437,)\n",
      "(360, 8, 8) (360,)\n"
     ]
    }
   ],
   "source": [
    "# 1. データロード\n",
    "dataset = datasets.load_digits()\n",
    "images = dataset['images']\n",
    "target = dataset['target']\n",
    "\n",
    "# 学習データと検証データ分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "# 前処理\n",
    "# 2-1.ラベルのone-hot encoing\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "# 2-2. 画像の標準化\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_val = (X_val - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03c446d-fce6-429e-9144-ebd427ce54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# パラメータの初期化\n",
    "m, n = X_train.shape\n",
    "nh = 30\n",
    "class_num = 10\n",
    "# パラメータの初期化\n",
    "# W1 = torch.randn((nh, n), requires_grad=True) # 出力 x 入力\n",
    "# Kaiming初期化を使って，softmaxの入力が大きくならないようにする\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "# W2 = torch.randn((class_num, nh), requires_grad=True) # 出力 x 入力\n",
    "# Kaiming初期化を使って，softmaxの入力が大きくならないようにする\n",
    "W2 = torch.randn((class_num, nh)) * torch.sqrt(torch.tensor(2./nh))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad=True) # 1 x nh\n",
    "# スクラッチのbackward\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train)\n",
    "# PytorchのAutograd\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb041c79-dfe2-47e1-a226-1b7372b45e28",
   "metadata": {},
   "source": [
    "### MLPの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da60e411-dc68-45c4-adab-fea848656edb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: train loss:1.8424878443280857, val loss: 3.9936957359313965, val accuracy: 0.4333333373069763\n",
      "epoch: 2: train loss:0.937017884105444, val loss: 2.586479663848877, val accuracy: 0.6333333253860474\n",
      "epoch: 3: train loss:0.5741765623291334, val loss: 1.9767118692398071, val accuracy: 0.7222222089767456\n",
      "epoch: 4: train loss:0.4157436192035675, val loss: 1.684888243675232, val accuracy: 0.7805555462837219\n",
      "epoch: 5: train loss:0.330823608674109, val loss: 1.3481305837631226, val accuracy: 0.8111110925674438\n",
      "epoch: 6: train loss:0.27900383714586496, val loss: 1.1966313123703003, val accuracy: 0.8305555582046509\n",
      "epoch: 7: train loss:0.244715781416744, val loss: 1.0972546339035034, val accuracy: 0.8444444537162781\n",
      "epoch: 8: train loss:0.2180399401113391, val loss: 1.1595005989074707, val accuracy: 0.8416666388511658\n",
      "epoch: 9: train loss:0.19901746977120638, val loss: 1.117865800857544, val accuracy: 0.8527777791023254\n",
      "epoch: 10: train loss:0.1831873545112709, val loss: 1.0679675340652466, val accuracy: 0.8638888597488403\n",
      "epoch: 11: train loss:0.16938012007934353, val loss: 1.104913592338562, val accuracy: 0.8666666746139526\n",
      "epoch: 12: train loss:0.1601474864097933, val loss: 0.9682801365852356, val accuracy: 0.8805555701255798\n",
      "epoch: 13: train loss:0.15080088757288954, val loss: 0.9741123914718628, val accuracy: 0.8861111402511597\n",
      "epoch: 14: train loss:0.14275279253100356, val loss: 1.0946927070617676, val accuracy: 0.8777777552604675\n",
      "epoch: 15: train loss:0.13544496792989472, val loss: 1.0747473239898682, val accuracy: 0.8805555701255798\n",
      "epoch: 16: train loss:0.12906482877830663, val loss: 1.0224448442459106, val accuracy: 0.8861111402511597\n",
      "epoch: 17: train loss:0.12330308890280624, val loss: 1.0464463233947754, val accuracy: 0.8805555701255798\n",
      "epoch: 18: train loss:0.11888861710516115, val loss: 1.2812436819076538, val accuracy: 0.8666666746139526\n",
      "epoch: 19: train loss:0.11326738656498492, val loss: 1.2375127077102661, val accuracy: 0.8694444298744202\n",
      "epoch: 20: train loss:0.10913140101668735, val loss: 1.2554492950439453, val accuracy: 0.8694444298744202\n",
      "epoch: 21: train loss:0.1046960469102487, val loss: 1.1936596632003784, val accuracy: 0.8694444298744202\n",
      "epoch: 22: train loss:0.10142948656963806, val loss: 1.1141183376312256, val accuracy: 0.8916666507720947\n",
      "epoch: 23: train loss:0.09689547466890265, val loss: 0.952652633190155, val accuracy: 0.894444465637207\n",
      "epoch: 24: train loss:0.09502870492481937, val loss: 1.027391791343689, val accuracy: 0.894444465637207\n",
      "epoch: 25: train loss:0.09175925864838064, val loss: 1.104401707649231, val accuracy: 0.894444465637207\n",
      "epoch: 26: train loss:0.0889522972671936, val loss: 1.133166790008545, val accuracy: 0.8861111402511597\n",
      "epoch: 27: train loss:0.08589667039147268, val loss: 1.1454565525054932, val accuracy: 0.8861111402511597\n",
      "epoch: 28: train loss:0.08378852725339432, val loss: 1.0784574747085571, val accuracy: 0.894444465637207\n",
      "epoch: 29: train loss:0.08137082223159571, val loss: 1.076101303100586, val accuracy: 0.894444465637207\n",
      "epoch: 30: train loss:0.07878678621879469, val loss: 1.1795514822006226, val accuracy: 0.8861111402511597\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.03\n",
    "batch_size = 30\n",
    "num_batches = np.ceil(len(y_train) / batch_size).astype(int)\n",
    "loss_log = []\n",
    "# 3. パラメータの初期化\n",
    "# パラメータの初期化\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "W2 = torch.randn((class_num, nh)) * torch.sqrt(torch.tensor(2./nh))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad=True) # 1 x nh\n",
    "\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "# 5. for文で学習ループ作成\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    running_loss = 0\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        # mini batch作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        # 6. 入力データXおよび教師ラベルのYを作成\n",
    "        y_true_ = y_train[batch_indices, :] # データ数xクラス数\n",
    "        X = X_train[batch_indices, :] # データ数 x 特徴量数\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "        # 7. Z計算\n",
    "        # Z = X@W.T + b # -> MLP\n",
    "        Z1 = linear(X, W1, b1)\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = linear(A1, W2, b2)\n",
    "        loss, A2 = softmax_cross_entropy(Z2, y_true_)\n",
    "\n",
    "        # 8. softmaxで予測計算\n",
    "        # y_pred = softmax(Z)\n",
    "\n",
    "        # 9. 損失計算\n",
    "        # loss = cross_entropy(y_true_, y_pred) #-> softmax_cross_entropy\n",
    "        loss_log.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 10. 勾配計算\n",
    "        # loss.backward() # -> scratchのbackward\n",
    "        Z2.grad_ = (A2 - y_true_) / X.shape[0]\n",
    "        linear_backward(A1, W2, b2, Z2)\n",
    "        relu_backward(Z1, A1)\n",
    "        linear_backward(X, W1, b1, Z1)\n",
    "\n",
    "        # 11. パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            W1 -= learning_rate * W1.grad_ # .grad -> .grad_\n",
    "            W2 -= learning_rate * W2.grad_ # .grad -> .grad_\n",
    "            b1 -= learning_rate * b1.grad_\n",
    "            b2 -= learning_rate * b2.grad_\n",
    "\n",
    "        # 12. 勾配初期化\n",
    "        # W.grad.zero_() # .grad_ = None\n",
    "        # b.grad.zero_()\n",
    "            W1.grad_ = None\n",
    "            W2.grad_ = None\n",
    "            b1.grad_ = None\n",
    "            b2.grad_ = None\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        # Z_val = X_val@W.T + b # -> MLP\n",
    "        Z1_val = linear(X_val, W1, b1)\n",
    "        A1_val = relu(Z1_val)\n",
    "        Z2_val = linear(A1_val, W2, b2)\n",
    "        val_loss, A2_val = softmax_cross_entropy(Z2_val, y_val)\n",
    "        # y_pred_val = softmax(Z_val)\n",
    "\n",
    "        # val_loss = cross_entropy(y_val, y_pred_val) #-> softmax_cross_entropy\n",
    "        val_accuracy = torch.sum(torch.argmax(A2_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy.item())\n",
    "        \n",
    "    # 13. 損失ログ出力\n",
    "    print(f'epoch: {epoch+1}: train loss:{running_loss/num_batches}, val loss: {val_loss.item()}, val accuracy: {val_accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a17def-3a28-4584-b10a-6ca0d1d608cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xffff59c1b9a0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGdCAYAAADNHANuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIPElEQVR4nO3de3xT9f0/8FeSNklpm7Sl9EIvUO4gVyuXwgSUSmF+/VLdBZkOVMDhYNPhLtY5nfp15TfnJpsORGS4MQRRwYlys9wUyh0mBbkUCi3QtNya9Jq2yfn98UnSBnpLmuQk7ev5eJxHTk5OkndCSF79nM/5fBSSJEkgIiIikplS7gKIiIiIAIYSIiIi8hMMJUREROQXGEqIiIjILzCUEBERkV9gKCEiIiK/wFBCREREfoGhhIiIiPxCkNwFtIXVasWVK1cQHh4OhUIhdzlERETUBpIkoby8HN27d4dS2Xo7SECEkitXriApKUnuMoiIiMgNRUVFSExMbHW/gAgl4eHhAMSL0ul0MldDREREbWEymZCUlOT4HW9NQIQS+yEbnU7HUEJERBRg2tr1gh1diYiIyC8wlBAREZFfYCghIiIiv8BQQkRERH6BoYSIiIj8AkMJERER+QWGEiIiIvILDCVERETkFxhKiIiIyC+0K5QsWrQICoUCzzzzTIv7rVu3DgMGDIBWq8WQIUPwxRdftOdpiYiIqANyO5QcPHgQ77zzDoYOHdrifnv37sWMGTMwe/ZsHD16FJmZmcjMzEReXp67T01EREQdkFuhpKKiAo888gjeffddREZGtrjv4sWLMWXKFPzqV7/CwIED8eqrr+LOO+/EW2+95VbBRERE1DG5FUrmz5+P+++/H+np6a3um5ube9t+GRkZyM3NbfY+ZrMZJpPJafGK/cuA//wMuH7OO49PREREbebyLMFr1qzBkSNHcPDgwTbtbzAYEBsb67QtNjYWBoOh2ftkZ2fj5ZdfdrU0132zBrh8GOhzH9C1t/efj4iIiJrlUktJUVERnn76afz73/+GVqv1Vk3IysqC0Wh0LEVFRd55ooge4rLsoncen4iIiNrMpZaSw4cPo7S0FHfeeadjm8Viwe7du/HWW2/BbDZDpVI53ScuLg4lJSVO20pKShAXF9fs82g0Gmg0GldKc0+kLZTcZCghIiKSm0stJZMmTcLx48dx7Ngxx3LXXXfhkUcewbFjx24LJACQlpaGnJwcp23btm1DWlpa+yr3BLaUEBER+Q2XWkrCw8MxePBgp22hoaHo2rWrY/vMmTORkJCA7OxsAMDTTz+NCRMm4I033sD999+PNWvW4NChQ1i2bJmHXkI7sKWEiIjIb3h8RNfCwkIUFxc7ro8dOxarV6/GsmXLMGzYMHz00UfYsGHDbeFGFo6WkkJAkuSthYiIqJNTSJL//xqbTCbo9XoYjUbodDrPPXB9LfB/MQAk4NkzQHhsq3chIiKitnH197tzz30TpAZ0CWKd/UqIiIhk1blDCcB+JURERH6CocTRr+SCrGUQERF1dgwlbCkhIiLyCwwlHKuEiIjILzCUsKWEiIjILzCU2FtKjJcAS728tRAREXViDCXh8YBKDUgWwHRZ7mqIiIg6LYYSpRLQJ4l19ishIiKSDUMJ0NCvpKxQ3jqIiIg6MYYSoKFfCTu7EhERyYahBGjUUsJQQkREJBeGEoAtJURERH6AoQTgAGpERER+gKEEaDh8U14M1NXIWwsREVEnxVACAF26AsGhYt1YJG8tREREnRRDCQAoFBxunoiISGYMJXaOfiUXZC2DiIios2IosWNLCRERkawYSux4Bg4REZGsGErs2FJCREQkK4YSO7aUEBERyYqhxM7eUlJ9E6gxyVsLERFRJ8RQYqcJB0KixDpbS4iIiHyOoaQx9ishIiKSDUNJY+xXQkREJBuGksbYUkJERCQbhpLG2FJCREQkG4aSxthSQkREJBuGksYieorLsouAJMlaChERUWfDUNJYRBIABVBXBVRek7saIiKiToWhpLEgDRAeL9bZr4SIiMinXAolS5YswdChQ6HT6aDT6ZCWloZNmzY1u//KlSuhUCicFq1W2+6ivcrRr+SCrGUQERF1NkGu7JyYmIhFixahb9++kCQJ77//PqZNm4ajR4/ijjvuaPI+Op0Op0+fdlxXKBTtq9jbInoAhblsKSEiIvIxl0LJAw884HT9tddew5IlS7Bv375mQ4lCoUBcXJz7FfpaRLK4LCuUtw4iIqJOxu0+JRaLBWvWrEFlZSXS0tKa3a+iogI9evRAUlISpk2bhhMnTrT62GazGSaTyWnxGZ4WTEREJAuXQ8nx48cRFhYGjUaDefPmYf369Rg0aFCT+/bv3x8rVqzAp59+ilWrVsFqtWLs2LG4dOlSi8+RnZ0NvV7vWJKSklwt030cQI2IiEgWCklybUCO2tpaFBYWwmg04qOPPsLy5cuxa9euZoNJY3V1dRg4cCBmzJiBV199tdn9zGYzzGaz47rJZEJSUhKMRiN0Op0r5bqurBB4cwigDAZeKAGUKu8+HxERUQdlMpmg1+vb/PvtUp8SAFCr1ejTpw8AIDU1FQcPHsTixYvxzjvvtHrf4OBgjBgxAvn5+S3up9FooNFoXC3NM3QJgDIIsNYB5cWAPlGeOoiIiDqZdo9TYrVanVo1WmKxWHD8+HHEx8e392m9R6lqCCLsV0JEROQzLrWUZGVlYerUqUhOTkZ5eTlWr16NnTt3YsuWLQCAmTNnIiEhAdnZ2QCAV155BWPGjEGfPn1QVlaG119/HRcvXsScOXM8/0o8KaKHGKek7CKAcXJXQ0RE1Cm4FEpKS0sxc+ZMFBcXQ6/XY+jQodiyZQvuu+8+AEBhYSGUyobGl5s3b2Lu3LkwGAyIjIxEamoq9u7d26b+J7KK7AEUgC0lREREPuRyR1c5uNpRpt12/wnY/iowbAbw4FLvPx8REVEH5OrvN+e+aUpkT3HJlhIiIiKfYShpCscqISIi8jmGkqbYR3U1XQHq23ZmEREREbUPQ0lTQrsBwV0ASICx5dFniYiIyDMYSpqiUDRMzHfzgqylEBERdRYMJc1hvxIiIiKfYihpDmcLJiIi8imGkuawpYSIiMinGEqaw5YSIiIin2IoaQ5bSoiIiHyKoaQ59paSquuAuULeWoiIiDoBhpLmaPWANkKss7WEiIjI6xhKWsJ+JURERD7DUNIS+wBqbCkhIiLyOoaSlkSwpYSIiMhXGEpaEtlTXLKlhIiIyOsYSlriOC24UN46iIiIOgGGkpY07ugqSfLWQkRE1MExlLTE3tG1thyovilvLURERB0cQ0lLgkOAsFixfvOCrKUQERF1dAwlreFw80RERD7BUNIaDqBGRETkEwwlrWFLCRERkU8wlLSGLSVEREQ+wVDSGraUEBER+QRDSWsiGw2gZrXKWwsREVEHxlDSGl0ioFABllqgwiB3NURERB0WQ0lrVEGAPkGss18JERGR1zCUtAX7lRAREXkdQ0lb8AwcIiIir2MoaYuInuKSLSVERERew1DSFmwpISIi8jqXQsmSJUswdOhQ6HQ66HQ6pKWlYdOmTS3eZ926dRgwYAC0Wi2GDBmCL774ol0Fy4J9SoiIiLzOpVCSmJiIRYsW4fDhwzh06BDuvfdeTJs2DSdOnGhy/71792LGjBmYPXs2jh49iszMTGRmZiIvL88jxfuMvaXEdBmw1MlbCxERUQelkCRJas8DREVF4fXXX8fs2bNvu2369OmorKzExo0bHdvGjBmD4cOHY+nSpW1+DpPJBL1eD6PRCJ1O155y3WO1Aq/FARYz8POjQFQv39dAREQUYFz9/Xa7T4nFYsGaNWtQWVmJtLS0JvfJzc1Fenq607aMjAzk5ua2+Nhmsxkmk8lpkZVSCUQki3X2KyEiIvIKl0PJ8ePHERYWBo1Gg3nz5mH9+vUYNGhQk/saDAbExsY6bYuNjYXB0PLIqNnZ2dDr9Y4lKSnJ1TI9L5L9SoiIiLzJ5VDSv39/HDt2DPv378dTTz2FWbNm4eTJkx4tKisrC0aj0bEUFRV59PHdEsEzcIiIiLwpyNU7qNVq9OnTBwCQmpqKgwcPYvHixXjnnXdu2zcuLg4lJSVO20pKShAXF9fic2g0Gmg0GldL8y62lBAREXlVu8cpsVqtMJvNTd6WlpaGnJwcp23btm1rtg+KX2NLCRERkVe51FKSlZWFqVOnIjk5GeXl5Vi9ejV27tyJLVu2AABmzpyJhIQEZGdnAwCefvppTJgwAW+88Qbuv/9+rFmzBocOHcKyZcs8/0q8jS0lREREXuVSKCktLcXMmTNRXFwMvV6PoUOHYsuWLbjvvvsAAIWFhVAqGxpfxo4di9WrV+OFF17A888/j759+2LDhg0YPHiwZ1+FL9hbSiqvArVVgLqLvPUQERF1MO0ep8QXZB+nBAAkCViUDJhNwE/3AzED5KmDiIgoQPhsnJJOR6HgcPNERERexFDiCk7MR0RE5DUMJa5gSwkREZHXMJS4wtFSckHWMoiIiDoihhJXsKWEiIjIaxhKXOFoKSmUtw4iIqIOiKHEFfaZgs1GoPqmvLUQERF1MAwlrlCHAqHdxDrPwCEiIvIohhJXsV8JERGRVzCUuIpjlRAREXkFQ4mr2FJCRETkFQwlrmJLCRERkVcwlLiKLSVERERewVDiKvtpwWWFYuZgIiIi8giGElfpkwAogPoaoKJE7mqIiIg6DIYSVwWpAV2CWGe/EiIiIo9hKHFHJPuVEBEReRpDiTsieAYOERGRpzGUuMPRUnJB1jKIiIg6EoYSd7ClhIiIyOMYStzBPiVEREQex1DiDntLifEyYKmXtxYiIqIOgqHEHeHxgEoNSBbAdEnuaoiIiDoEhhJ3KJW2QdTAfiVEREQewlDiLke/kkJ56yAiIuogGErcxYn5iIiIPIqhxF2RPC2YiIjIkxhK3MWWEiIiIo9iKHFXdF9xacgD6s3y1kJERNQBMJS4K+YOICwOqKsELnwtdzVEREQBj6HEXUol0G+yWD+zRd5aiIiIOgCXQkl2djZGjhyJ8PBwxMTEIDMzE6dPn27xPitXroRCoXBatFptu4r2G/2miMszmwFJkrcWIiKiAOdSKNm1axfmz5+Pffv2Ydu2bairq8PkyZNRWVnZ4v10Oh2Ki4sdy8WLHaRzaMoEQKURnV2vthzOiIiIqGVBruy8efNmp+srV65ETEwMDh8+jPHjxzd7P4VCgbi4OPcq9GeaMCDlbiD/S9FaEjNA7oqIiIgCVrv6lBiNRgBAVFRUi/tVVFSgR48eSEpKwrRp03DixIn2PK1/cRzCYb8SIiKi9nA7lFitVjzzzDMYN24cBg8e3Ox+/fv3x4oVK/Dpp59i1apVsFqtGDt2LC5dan4iO7PZDJPJ5LT4rb62zq5F+4CqG/LWQkREFMDcDiXz589HXl4e1qxZ0+J+aWlpmDlzJoYPH44JEybgk08+Qbdu3fDOO+80e5/s7Gzo9XrHkpSU5G6Z3hfZA4gZBEhWID9H7mqIiIgClluhZMGCBdi4cSN27NiBxMREl+4bHByMESNGID8/v9l9srKyYDQaHUtRUZE7ZfpOvwxxeWZzy/sRERFRs1wKJZIkYcGCBVi/fj22b9+OlJQUl5/QYrHg+PHjiI+Pb3YfjUYDnU7ntPg1e7+S/G2ApV7eWoiIiAKUS6Fk/vz5WLVqFVavXo3w8HAYDAYYDAZUV1c79pk5cyaysrIc11955RVs3boV58+fx5EjR/Doo4/i4sWLmDNnjudehdwSRwIhkUCNESjaL3c1REREAcmlULJkyRIYjUZMnDgR8fHxjmXt2rWOfQoLC1FcXOy4fvPmTcydOxcDBw7Ed7/7XZhMJuzduxeDBg3y3KuQm1LV0OH1zCZ5ayEiIgpQCkny/6FITSYT9Ho9jEaj/x7KyfsE+OhxILofsOCg3NUQERHJztXfb8594ym97wWUQcC1M8D1c3JXQ0REFHAYSjwlJAJIThPrZ7fKWgoREVEgYijxpMYT9BEREZFLGEo8yR5KLuwBavx4FFoiIiI/xFDiSdF9gKjegLUOOL9D7mqIiIgCCkOJp3GCPiIiIrcwlHiaY8j5LYDVKm8tREREAYShxNOS0wCNDqi6Blw5Inc1REREAYOhxNOC1GLMEoBn4RAREbmAocQbeGowERGRyxhKvKHvfQAUgOE4YLwsdzVEREQBgaHEG0KjxczBAHCWZ+EQERG1BUOJtzQ+C4eIiIhaxVDiLf2nisvzO4HaKllLISIiCgQMJd4SMwjQJwH1NcCFr+SuhoiIyO8xlHiLQtHoEA7PwiEiImoNQ4k3NR5yXpLkrYWIiMjPMZR4U8+7geAugOmyOD2YiIiImsVQ4k3BWqDXRLHOs3CIiIhaxFDibexXQkRE1CYMJd7Wd7K4vHwYqCiVtxYiIiI/xlDibbruQPwwABJwdpvc1RAREfkthhJf4AR9RERErWIo8QV7v5Jz24H6WnlrISIi8lMMJb4QPwIIjQFqK4CLe+SuhoiIyC8xlPiCUgn0s3V45anBRERETWIo8RVHv5JNHN2ViIioCQwlvtLrHkClBm5eAK6dlbsaIiIiv8NQ4iuaMDHsPMCzcIiIiJrAUOJLjSfoIyIiIicMJb5k7+xamAtU35S3FiIiIj/DUOJLkT2BbgMByQLk58hdDRERkV9xKZRkZ2dj5MiRCA8PR0xMDDIzM3H69OlW77du3ToMGDAAWq0WQ4YMwRdffOF2wQHPMUEfD+EQERE15lIo2bVrF+bPn499+/Zh27ZtqKurw+TJk1FZWdnsffbu3YsZM2Zg9uzZOHr0KDIzM5GZmYm8vLx2Fx+Q7P1K8rcBlnp5ayEiIvIjCklyf9CMq1evIiYmBrt27cL48eOb3Gf69OmorKzExo0bHdvGjBmD4cOHY+nSpW16HpPJBL1eD6PRCJ1O5265/sFSD/ypj+hT8vhmoEea3BURERF5hau/3+3qU2I0GgEAUVFRze6Tm5uL9PR0p20ZGRnIzc1tz1MHLlUQ0Oc+sX5mk7y1EBER+RG3Q4nVasUzzzyDcePGYfDgwc3uZzAYEBsb67QtNjYWBoOh2fuYzWaYTCanpUNhvxIiIqLbuB1K5s+fj7y8PKxZs8aT9QAQHWr1er1jSUpK8vhzyKrPJEChAq6eAm4UyF0NERGRX3ArlCxYsAAbN27Ejh07kJiY2OK+cXFxKCkpcdpWUlKCuLi4Zu+TlZUFo9HoWIqKitwp03+FRALJtr4kh96TtxYiIiI/4VIokSQJCxYswPr167F9+3akpKS0ep+0tDTk5DiPybFt2zakpTXfwVOj0UCn0zktHc64n4vL3L8Dhk56JhIREVEjLoWS+fPnY9WqVVi9ejXCw8NhMBhgMBhQXV3t2GfmzJnIyspyXH/66aexefNmvPHGGzh16hR+//vf49ChQ1iwYIHnXkUg6pcBDHxADKS28ReA1Sp3RURERLJyKZQsWbIERqMREydORHx8vGNZu3atY5/CwkIUFxc7ro8dOxarV6/GsmXLMGzYMHz00UfYsGFDi51jO40p/w9QhwGXDgBH3pe7GiIiIlm1a5wSX+lQ45Tcat8SYPNzgFYPLDgEhMXIXREREZFH+HScEvKAkXOBuKFAjRHY8lu5qyEiIpINQ4ncVEHAA28CUADHPwTO7ZC7IiIiIlkwlPiDhFRg1Fyx/vmzQF2NvPUQERHJgKHEX9z7AhAWB9w4B3z9Z7mrISIi8jmGEn+h1QNTF4n1r/8CXDsrbz1EREQ+1ulDibneAovVT05AGpQpJuuz1IqxS/z/xCgiIiKP6dSh5Mfv7cfgl7bg+GWj3KUICgVw/5+AoBDgwlfAfz0/rxAREZG/6tShRKFQoM4i+U8oAYDInsCEX4v1rb8Fqm7IWg4REZGvdOpQMiRBDOSSd8mPQgkAjP0Z0G0gUHUd2Pai3NUQERH5RCcPJREA4F8tJQCgCraNXQLg6L+Ai3tlLYeIiMgXOncoSdQDAM6UlKOmziJzNbdIHgPcOVOsb/wFUF8rbz1ERERe1qlDSXe9FlGhatRbJZwylMtdzu3SXwa6dAWungJy/yZ3NURERF7VqUOJQqHA4ATRWuJ3h3AAoEsUMPk1sb7rj8CNAnnrISIi8qJOHUoAP+7sajfsYaDn3UB9DfDFLzl2CRERdVgMJf7a2dVOoQD+5y+ASg3kfwmc3CB3RURERF7BUOLPnV3tovsC3/mFWN/0HFDjpwGKiIioHTp9KPH7zq5231kIRPUGKgzA9v+TuxoiIiKP6/ShxO87u9oFa4H73xDrB94FLh+Wtx4iIiIP6/ShBAiAzq52ve8BhvwQgAR89gxgqZe7IiIiIo9hKEEAdHZtLOM1QKsHDN8AB5bJXQ0REZHHMJQgQDq72oXFiEHVAGDHH4DKa/LWQ0RE5CEMJQigzq52d84C4ocBteXA7j/JXQ0REZFHMJQggDq72imVQPrvxfrB5cDNC3JWQ0RE5BEMJTYB09nVrve9QK+JgLUO2P6a3NUQERG1G0OJTUB1drWzt5YcXwcUfyNrKURERO3FUGITUJ1d7bqPAAZ/D4AE5LwsdzVERETtwlBiE3CdXe3u+S2gDBLz4hTslrsaIiIitzGU2ARcZ1e7rr2B1MfF+raXOIswEREFLIaSRobaQknAdHa1m/BrIDgUuHIEOPmp3NUQERG5haGkkYBsKQHEgGpjF4j1nFcAS5289RAREbmBoaSRgOzsape2AOgSDdw4Bxz5p9zVEBERuYyhpJGA7ewKAFqdOIwDALv+H1BbKW89RERELnI5lOzevRsPPPAAunfvDoVCgQ0bNrS4/86dO6FQKG5bDAaDuzV7TcB2drVLfRyI6AFUlAD7/i53NURERC5xOZRUVlZi2LBhePvtt1263+nTp1FcXOxYYmJiXH1qnwjYzq4AEKQG7v2dWP96MVB5Xd56iIiIXBDk6h2mTp2KqVOnuvxEMTExiIiIcPl+vhbQLSWAGExt72LAcBz46k/AlGy5KyIiImoTn/UpGT58OOLj43Hfffdhz549vnpalwV0Z1fANlmfbXTXg8uBmxflrYeIiKiNvB5K4uPjsXTpUnz88cf4+OOPkZSUhIkTJ+LIkSPN3sdsNsNkMjktvhLQnV3tet8LpIwHLLXAjj/IXQ0REVGbeD2U9O/fHz/5yU+QmpqKsWPHYsWKFRg7diz+8pe/NHuf7Oxs6PV6x5KUlOTtMh0CvrMrACgUDZP1fbMWMOTJWg4REVFbyHJK8KhRo5Cfn9/s7VlZWTAajY6lqKjIh9UFeGdXu4RU4I4Hwcn6iIgoUMgSSo4dO4b4+Phmb9doNNDpdE6LLwV8S4ndvb8Tk/Wd3QoUfCV3NURERC1y+eybiooKp1aOgoICHDt2DFFRUUhOTkZWVhYuX76Mf/5TjCr65ptvIiUlBXfccQdqamqwfPlybN++HVu3bvXcq/CwWzu7aoNVMlfkpq69gTtnAYfeA758CZiTIw7tEBER+SGXW0oOHTqEESNGYMSIEQCAhQsXYsSIEXjxxRcBAMXFxSgsLHTsX1tbi2effRZDhgzBhAkT8N///hdffvklJk2a5KGX4HkdorOr3YTfAMFdgMuHgW//I3c1REREzVJIkv/PdW8ymaDX62E0Gn12KGfmigPYfeYqXs0cjB+P6eGT5/Sa7a8Bu/8IdO0D/HQ/oHK5gYyIiMhlrv5+c+6bZnSIzq52Y38GdOkKXM8Hjv5L7mqIiIiaxFDSjA7T2RUQk/WN/5VY37kIqK2Stx4iIqImMJQ0I+BHdr3VXU8AEclAhQHYv0TuaoiIiG7DUNKMDtXZFQCCNI0m63sTqLohazlERES3YihphkKhwJCOdAgHAAZ/H4gdAphNwFdvyF0NERGRE4aSFgzpSJ1dAdtkfb8X6weWATcvyFkNERGRE4aSFtg7u37TUVpKAKDPJKDn3WKyvpUPACUn5K6IiIgIAENJi+ydXc92lM6ugBjR9X//CkSmAMZC4L3JwOnNcldFRETEUNKSDtfZ1S6qFzB3u2gxqa0APngY2Ps3wP/H0SMiog6MoaQFHbKzq12XKODRT8TcOJCArS8A/1kA1NfKXRkREXVSDCWt6HCdXRsLUgMPLAYysgGFEji6CvhXJlB5Xe7KiIioE2IoaUWH7OzamEIBpP0U+NGHgDocuLgHWH4vUHpK7sqI5HX1DLB6OvD5s0Dex4CpWO6KiDo8zszWils7u2qDVTJX5CV97wPmbBNfwjcvAO/dB3z/H0DfdLkrI/K9GhOwZoaYLwoADi4Xl1G9gB5jgR7jxGVEDxHsicgjGEpaYe/seqOyFqcM5RieFCF3Sd4TMxCYuwNY+yhQuBdY/QNxaGf0T/jFS52HJIn+VdfzAV0iMPB/gIt7AcNx4MZ5sRxdJfYN724LKbag0q2/e/9XzBVARQlQbgDKi8V65TUgbgjQLwNQh3r2NRL5KYaSVtg7u+46cxXHLxs7digBgNCuwMwNwMaFwLFVwObfAFdPAd99HVAFy10dkfftWwKc/BRQBgM/fB9IvEtsry4Dig6IQ5wX9wJXjgLlV4C8j8QCiNm4k9MagkpkClB5VQSN8pKGwFFuEEuFQWyvbeHsvuAuQL8pwOCHgD73AcFar78FRHJhKGkDeyjpkJ1dmxKkAaa9Jf7q2/YicPgfwI1zwA/eF2ftEHVUhfuAbbY5oqZkNwQSAAiJAPpNFgsgZtu+fEgElIt7gKKDQNV14NRGsbhKHQaExQLh8UB4LKDRAed3iMOpJz4RizocGHC/CCi97hGd1Yk6EIaSNujwnV2bolAA434ORPcDPp4NFOwGlk8SHWKj+8pdHZHnVZQC6x4DrPVinqiRc1reX90FSBkvFkCcTl98zBZS9oqAYzaKcBEWC4THNSxht67HAprw259DkoArR4C8T4ATGwDTJeCbNWLRRgADHxABped4QMWvcwp8Ckny/xGzTCYT9Ho9jEYjdDqdz5//clk1xi3ajiClAnkvZ3Tczq7NKTkBrH5YjACr0QM/XAn0vlfuqog8x1IvToe/8BXQbQAwJwfQhLXvMa0WoN4swosnWK3ApQO2gLIeqCxtuK1LNDBomggoyWmAspN9R5HfcvX3m6cEt0GHHdm1rWLvECPAJo0Wf/mt+j6Q+3fxpUvUEex4TQQSdRjww3+1P5AAIhh4KpAAYkLN5DHAd/8IPHsKmPUZkPo4EBIFVF0DDr0HrLwf+PMgYNNzwKVDHKWZAg5DSRt06JFd2yqsGzDzP8DQhwHJAmzJApaMA85s5RcfBbZTXwBf/1ms/+/fgG795K2nLZQqcdjogTeBX54BHv0YGP6IaMmsMAD7l4jDre/eA3zzIUdqppZZLaLjth9gKGmjDj2ya1sFa4EHlwJTXwe0euDqt+K04X/+r998oIlccqMAWD9PrI9+Shz+CDSqYKBPOpD5d+BXZ4EZa4AhPwBUGvH/8pO5wOKhwO4/cbRmut2FPcCyicB7GcDNi3JXw1DSVp2ys2tTFApg9JPAz48BY38GqNSiE+yyicDHc7z/oS49JToR1lZ693mo46urBj78sTgkmTQauO8VuStqvyAN0H8q8L3lwMKTwD0viE625cXA9leBvwwC/vNzjthMIpCv/TGw8ruA4RsgSCuGf5AZO7q2Uafv7NqcmxeB7f8HHP9QXFepxWBrdz8LhER65jmunxOd+/I+Fq0zAKBQiYGlkseIH5TkMYCuu2eejzqHTxcAR/8lOonO+6rjfn7qzaJjbO7b4sfHrve9wJj54lLJv0/bRZLEH0r1NWKsGn8ebLLGJA5X5r4NWGrFvGepjwP3PA+ERnv86Vz9/WYoaSNJknDX/32J65W12DB/XMcfRM1VV44CW38nOgsC4nTF8b8ERj0p/npzVVmR+CLN+1icZmmnUosfkfIrt99Hn9QQUJJGiw66PAuBmnLkX2LUVoUS+PF6oNdEuSvyPkkSrYz7/g6c+hyA7as/uh8w5inRX8yTHXMDkaVedBquLgOqbwI1tsvqstbXrfXiMWIGAcNmAEN/KE759hdWC3Ds30DOqw1nbvWaKEbtjh3ktadlKPGiWSsOYNeZq3g1czB+PKaHbHX4LUkCzm4TA67ZWzQikoFJLwF3PNT6X2PlJWIkzbyPgaJ9DdsVKvGfZ/D3xMBRIRGA8ZIYB6LogNjXcByQrM6Ppw4Xg1/ZQ0riXU2PBUGdS/F/gfcmi79q7/2dCM+dzY0C4MAyEc7so8mGRAKpj4k/JDpqq5GduQK4dga4dha4dhq4elqs3zgPWOs88xwKpWiFGjZDfG8Fh3jmcd1x4Wtg83PiexIAonoDGX8QUxh4uVWHocSL/rTlNN7akY8f3pWIP35/mGx1+D2rBTi2WpxmWW6bWTV+ODD51YaBpuyqbgDffiaCyIWvGgULhZhLZPBDYvyF1poVzRVidM3C/SKkFB28fehuhVK0nqRMAHrfIx5fzi8K8r3qMmDZBDFKar8pwMMfdO5DFzUmMY/P/qVAma0/mDIIGJQJTPi1GNU5UEmSGOL/6mlbADnTED5Ml5q/n0IpWnpDImyXkW1ft9SKQe7++wFQtL/hMTU64I5MYNiPxB9Jvjq8c6NAjFD87We2OvTAxN8AI+f6bDRghhIv2pxnwLxVhzEwXodNT98tWx0Bo7ZSNBV/vbghIPTNEP8pruWLIHIup6HZEwAS7hItIndktu+vNasFKP1WBBR7UCkrdN4nSCvmJ+l9r1hiBnn+y6K+Fig9KQ5vXTsjAlH/KZ59DmobqxVY8yPgzCYxu+9Pdnmu31Ogs1qA01+IeX8u7hHb1GHA9H8FzkCJVqv4Pjn5aUMQqSlrfv/QGHHoqls/ILq/GKm6W38xyaIngur1c8B/14jF2Oi7J7Kn7fDOdCAqpf3P05QaE/DVG+L7195v5K4ngInPi/nNfIihxIvY2dVNFVeBXf9PzKHTOIDYxQ2xBZEHxX9YbzEVi9mPz+0Azm0HTJedbw+Pbwgove5x/T+vpV40BV852rAY8gCL2Xm/kXOBjNfc62vja5IkvlRPfCJOA9cl2JbutiUBCO0WGK0NX/0ZyHlZnCo7eyvQfbjcFfmnK8eALb8FLn4tWk2mvQ0Me1juqppXYxQtswfeFXN0NaZQigDqFD76iQDiq3m8rFbxvXPsA+DkBqC2ouG25LHA8BmiNVir98BzWUTL1/ZXRSsRIL7LMv7g1X4jLWEo8SJ2dm2na/niR+Hb/wBd+wJDvi/6msgxWJUkib+k8nNEQLnwNVBf3WgHBRA/DOgzSYSUxFHOzZ1Wq5ja3imAfAPUVd3+XNoIoPsIcQjq+DqxLX448IOV3vtLyRNMV4DPngbObm15P2UwoItvFFYSnNf1CeKvUjmDS8Fu4J/TxOHBB/4KpM6Sr5ZAUF8LbHiqYfbj9N8D457xr7NKSk8BB98VP/Z1tiECNHrxI580WoSPrn38a1bl2krRyfjYauD8Tjg6GwdpgQH/I75vVGrRQV+hanQZJP7/ONYb3W5fLy8W36/2fiNd+wCTX/NJv5GWMJR4GTu7eoClTvzH8qcvuLoacYgnP0e0pJQcd75dHQb0vFuECMNx8ddkU9PNq8PFX+Ddh4sg0v1O0fpjf61ntwGfPAlU3xBfoJlvi0nV/IkkiS/NzVliDA+VGhj7c/GXnOmKOB5vuiKWcgMcX6wtCYkSA3z1nSy+eH0527TpCvDOePGX4/BHxQzY/vTZ81dWK/Dli8Dev4nro54EpiyS94w2qwU4sxnY/w5QsKthe7eBwKi54pCIJ6YI8AXjZTGUwrEPRAurp2j1wITnxISSfjCLNEOJl7GzaydRbhB/ydhbUqqu3b5PUIhoTek+QiwJd4pe7a21CBgvAR890dARbvRTYuAuP/gCua11pPudQOYSIGZA0/tb6oCKEnE/Y6OwYrrccFle7HxmlEIp+g71nQz0vQ+IG+q9VhRLHbDyf0TgjB0CzNnGzs2u2rdEBFRIIkA/9K7v38OqG8CRfwIH32von6FQAv2/K8ZF6nl34AZN+0zQ/10rwonVIv6/WC3icLdksa1bGq3bt1sb1hVKYOD/AhOzfN5vpCUMJV7Gzq6dkNUqWk7yc8QPcNwQEUKi+7s/XbylDsh5Bdj7V3E9IRX4/j+ASJla3yRJjGGw+fmG1pF7ngfSfub+a7Sz1AGXDoqgc3YbUJLnfHtojAgnfe8Tx79DItx/rroa0aG57KI4w+bcDuD056JV6skdQNfe7XklnVfeJ8D6n4hOk8lpwMOrfdPaZTguWkWOrxOncAOic/Kds4CRs8WQA+TXvB5Kdu/ejddffx2HDx9GcXEx1q9fj8zMzBbvs3PnTixcuBAnTpxAUlISXnjhBTz22GNtfk5/CiXs7EoedXqTmHulpkw0u2YuBQZ817c1GC+L1pH8beJ6Qiow7e/Nt4544vnyt4mAcm5HQ38AQBwbTx5jCymTbz8jSpJEMLx5QYwmfPOC89LUoHqA+BEdcL93Xk9nceFr4IMfidAa3V9MAhiR5PnnsdSJU1gPvCs6iNrFDQFG/UT0RWNrV8DweijZtGkT9uzZg9TUVDz00EOthpKCggIMHjwY8+bNw5w5c5CTk4NnnnkGn3/+OTIyMtr0nP4UStjZlTyurBBY9xhw+bC4nrZAdCxUBXv3eb3ZOtJW9WagMFcElLNbRefjxnQJQM/viDMs7EHEqUNyE9RhQGSKaHWK7NnQWZnar+QksOp7IvyFxwOPfATEDfbMY5uKgSPvA4ffbwiXyiBxSGL0T0Tn1UA9RNOJ+fTwjUKhaDWU/OY3v8Hnn3+OvLyGJtuHH34YZWVl2Lx5c5uex59CCcDOruQF9bXAly+JcQUAcbbPD/4B6BO983zGy8BnPwfyvxTXvd060lY3CkRNZ7cCBV81HUAUSkCX2BA6HEuKuOwSxR8vbzJeAlZ9X4zarNEB01cBvSa491iSJM6MOrhcnJUiWcT20G5iPpa7Hu/4o8t2cK7+fnv9z6Hc3Fykp6c7bcvIyMAzzzzT7H3MZjPM5oaxHUwmk7fKc8uQBD12nbmK45fKADCUkAcEqYEp2WIwtw3zgUsHgKXfAR5cBvSb7LnnkSQxjsGW5wGzSYzZcc/zonXGV60jLYlKEWdRjJorZvG9sEe0IIV1awgf+iTvtyJR8/SJwBObxUB0F/eIlpMHl4rDKm1VXSZGPT34HnD9bMP25DRx1sjABwJjHB/yOK9/CxkMBsTGxjpti42NhclkQnV1NUJCbj82mJ2djZdfftnbpbltcIIY5Ob4Zf8KS9QBDHwAiB0sDucUHwNW/0CMD3Hv79ofGoyXbH1H7K0jdwGZf/ffocSDQ4C+6WIh/xISATxq6/x6cgPw8WxxxtrYBS3f78ox0Spy/KOGVjB1mDiVd+RsMQ0EdWp+8KfR7bKysrBw4ULHdZPJhKQkL3SoctOQRBFKzpaUo6bOws6u5FlRKWLE0a0viEnT9rwpTh/+/oqGpmyrRZyNUG8WLQr2dcdltfN10xXg6780tI7c+1vROsJZlMldwVpxxtiWeGD/EmDrb8XnbPL/OZ/iXVctZvw++J6Yn8ouZpAIIkOnc6JMcvB6KImLi0NJSYnTtpKSEuh0uiZbSQBAo9FAo/Hfprvuei26hqpxvbIWpwzl7OxKnhekAb77ujic8+nPRGfQxcPFYYv6mqaH628Lf28docCiVIrDjrruYuK3fW+LTqoPviNa5g6tEJ2pq2/a9g8WQ6qPnOPbiekoYHg9lKSlpeGLL75w2rZt2zakpaV5+6m9RqFQYLC9X8llI0MJec8dD4rBxdY9Joaxv3UeHUB80QdpxV+uQVoRaIK0jRbb9V4TxI8BW0fIkxQKYNzPxdk4G54SrSJFB51n4tUniU6rI34MhMXIVyv5PZdDSUVFBfLz8x3XCwoKcOzYMURFRSE5ORlZWVm4fPky/vnPfwIA5s2bh7feegu//vWv8cQTT2D79u348MMP8fnnn3vuVciAnV3JZ7r2Bp7cCdw4LwLFrYGDIYP8wdAfiA7Jax61BRKFmFpg5Bwx7gw/p9QGLoeSQ4cO4Z577nFct/f9mDVrFlauXIni4mIUFjZM05ySkoLPP/8cv/jFL7B48WIkJiZi+fLlbR6jxF/ZO7sevHATVqsEpZLNkORFSpWY2ZTIn/WaCMzNEad0D/gf/55wkvwSh5l3k7G6DuMWbUeFuR5LH03FlMFxcpdERETkV1z9/ZZxLvHApg8JxuPjegIAFuechdXq99mOiIjIrzGUtMPs76QgTBOEb4tN2HqypPU7EBERUbMYStohoosaj43tCQD4a85ZBMCRMCIiIr/FUNJO9taSk2wtISIiaheGknaKDG1oLVn8JVtLiIiI3MVQ4gFsLSEiImo/hhIPYGsJERFR+zGUeAhbS4iIiNqHocRDIkPVmDVWDDfP1hIiIiLXMZR40Jzv9EKoWoWTxSZsY2sJERGRSxhKPCgyVI3HbKO8vsnWEiIiIpcwlHgYW0uIiIjcw1DiYWwtISIicg9DiRewtYSIiMh1DCVeIM7E6QmArSVERERtxVDiJXPuZmsJERGRKxhKvCSqUWvJYs4gTERE1CqGEi+yt5acuGLCl9+Wyl0OERGRX2Mo8aIop74lZ9haQkRE1AKGEi9jawkREVHbMJR4GVtLiIiI2oahxAfm3N0LXdhaQkRE1CKGEh9gawkREVHrGEp8ZG6j1pIctpYQERHdhqHER5xaS3LYWkJERHQrhhIfsreW5F1mawkREdGtGEp8iK0lREREzWMo8TG2lhARETWNocTHokLVmJnWEwBbS4iIiBpjKJHB3LtTHK0l7351Xu5yiIiI/AJDiQy6hmkw/54+AIA/fHEKr3x2EhYrW0yIiKhzYyiRyU8n9sZzUwcAAFbsKcD8fx9BTZ1F5qqIiIjk41Yoefvtt9GzZ09otVqMHj0aBw4caHbflStXQqFQOC1ardbtgjsKhUKBeRN6Y/HDw6FWKbH5hAE/encfrleY5S6NiIhIFi6HkrVr12LhwoV46aWXcOTIEQwbNgwZGRkoLW3+TBKdTofi4mLHcvHixXYV3ZFMG56Af80eBZ02CEcKy/C9JXtx4Vql3GURERH5nMuh5M9//jPmzp2Lxx9/HIMGDcLSpUvRpUsXrFixotn7KBQKxMXFOZbY2Nh2Fd3RjO7VFZ/8dCwSI0Nw4XoVHlqyF4cv3pS7LCIiIp9yKZTU1tbi8OHDSE9Pb3gApRLp6enIzc1t9n4VFRXo0aMHkpKSMG3aNJw4caLF5zGbzTCZTE5LR9cnJhyf/HQshiTocaOyFj96dx825xXLXRYREZHPuBRKrl27BovFcltLR2xsLAwGQ5P36d+/P1asWIFPP/0Uq1atgtVqxdixY3Hp0qVmnyc7Oxt6vd6xJCUluVJmwIoJ12LNk2MwaUAMzPVWPPXvI3jv6wK5yyIiIvIJr599k5aWhpkzZ2L48OGYMGECPvnkE3Tr1g3vvPNOs/fJysqC0Wh0LEVFRd4u02+EaoLwzo9T8eiYZEgS8OrGk3j5sxM8ZZiIiDq8IFd2jo6OhkqlQklJidP2kpISxMXFtekxgoODMWLECOTn5ze7j0ajgUajcaW0DiVIpcSr0wYjMbILFm06hX/suYArZdVY/PAIaINVcpdHRETkFS61lKjVaqSmpiInJ8exzWq1IicnB2lpaW16DIvFguPHjyM+Pt61SjsZ+ynDf50xAmqVEltOlGAGTxkmIqIOzOXDNwsXLsS7776L999/H99++y2eeuopVFZW4vHHHwcAzJw5E1lZWY79X3nlFWzduhXnz5/HkSNH8Oijj+LixYuYM2eO515FB/a/w7rjX7NHQR8SjKOFZXhoyV4U8JRhIiLqgFw6fAMA06dPx9WrV/Hiiy/CYDBg+PDh2Lx5s6Pza2FhIZTKhqxz8+ZNzJ07FwaDAZGRkUhNTcXevXsxaNAgz72KDm50r674+Kk0PPaPg7h4vQoP/X0Pls+6C6k9ouQujYiIyGMUUgBMU2symaDX62E0GqHT6eQuRzal5TWYvfIQjl82Qh2kxB8eHIKHRiRAqVTIXRoREdFtXP395tw3ASQmXIu1PxGnDNfWW/HLdf9F+l924cODRaitt8pdHhERUbuwpSQA1Vus+PvOc1j+1XmYauoBAHE6LebcnYKHRyUjTOPyUTkiIiKPc/X3m6EkgFWY6/HB/kIs//o8SkzirBx9SDBmpfXArLE90TWs855WTURE8mMo6YTM9RZsOHoZ7+w6j/O2M3O0wUo8PDIZc+5OQWJkF5krJCKizoihpBOzWCVsPWHA33eew/HLRgCASqnAtGHd8ZMJvdE/LlzmComIqDNhKCFIkoS9565jyc5z+Dr/mmN7+sAYPDWxN08lJiIin2AoISffXCrD0l3nsCnPAPu/9KieUZg3sRfG9+2GIBVPwCIiIu9gKKEmnb9agWW7z+PjI5dQZxH/5PqQYNzdNxoT+8dgQr9u6BbOjrFEROQ5DCXUIoOxBiv2FGDtwSIYq+ucbhuSoMfE/t0wsX83DE+KhIqDshERUTswlFCb1Fus+O+lMuw8fRU7Tpci77LJ6XZ9SDDG9+uGif26YTxbUYiIyA0MJeSW0vIa7D5zDTtPl2L3mauOQdnshiTocU//bpjQPwbDkyLYikJERK1iKKF2q7dYcaxItKLsPHN7K0pEl2CMSemKO7rrMKi7Dnd01yNWp4FCwaBCREQNGErI40rLa7Dr9FXsPHMVXzXRigIAUaFqEVLi7UFFh5ToMLaoEBF1Ygwl5FX2VpRjRWU4ecWEE1dMyL9aAYv19o+RNliJAXENIWVQvA4D4nQIUatkqJyIiHyNoYR8rqbOgjMl5Y6QcrLYhG+LTaiqtdy2r1IB9OoWht7dQpESHYZe0aHoGR2KlOhQRIepeQiIiKgDYSghv2CxSrh4vdIRUk5cMeHkFSOuVdQ2e59wTZAjoDReekaHQh8S7MPqiYjIExhKyK+VmmpwstiEgmuVuHCtEuevVaLgWiUul1WjpU9i11C1I6QkR3VBrF6LOJ0WcXotYnVa6LRBbGUhIvIzDCUUkGrqLCi6UYXztrBSYAssF65VorTc3Or9Q4JViNVpEGsLKnE6rWM9VqdFrE6DmHAt1EEcVp+IyFdc/f0O8kFNRK3SBqvQNzYcfWNvn8m4wlzvCCoF1ypx6WYVDCYzSow1MJhqYKyuQ3WdBReuV+HC9aoWnyc6TI3oMI1tUaOrbb1rmNpxW9cwDbqGqqENZodcIiJfYighvxemCcLgBD0GJ+ibvL261oISUw1KTCKklJhqYDCaHdcNxhqUltegziLhWkWtrV9LeavPG64JsoUVTcNlqBqRoWpEdrFfBjvWQ9UqHkIiImoHhhIKeCFqFXraOsQ2x2qVcKOqFiWmGlyrqMX1CjOuV9TiWoXZFlTMuF7ZsK3OIqHcXI9yc32rrS92apUSEV2CERWqbnSpRlSXhuvh2mCEalQI0wQhVBPkuOwSrIKSY7oQUSfHUEKdglKpcBy2aY0kSTDV1OO6LbBcrzDjWmUtrpWL4HKzqg5lVbW4UWm/rIW53opaixWl5eY29YFpSqha5RRUGocXx3Z1EMK0QQjTqBzbw28JOGGaIPadIaKAxFBCdAuFQgF9SDD0IcHo1a1t96muteBGVS1uVtbiZlUtblbVNaxX1uKGLciYaupRaRZLhe3SPu5cZa0FlbUWt0NNY2qVEqGahpATpglCF1uLTBeNCl3UKnRRB9kuVQhRByG00bp9u9M+wSoEqRh2iMh7GEqIPCBErUKCOgQJESEu3U+SJNTUWR0BxX5ZWVuPCrPltgBTYbbcvq9tvcJcj5o6KwCg1mJFbZUVN6vqPPo61SoltMFKhNgCizZYhZBgZcO6WoUutssQW5AJCVZBq1ZBG6SENlhlW2zrQQ3rmkbbglUK9s8h6oQYSohkpFAoHD/g3cJbP7TUmnqLVbS42MJKeaPgUmm2oKrOgipzPapqLaiuE/tV11pQVWtBZa1Yr6y1oLpW7COWhtacWos4TCXmP2p/i05zlAo0BJggJTTBKmgaXwYpoQmyBRnbpWNbkNJpu1qlhDpIXAarlAgOUiJYpXBsD7Ztb7iuQLBtf7VKyb4+RD7EUELUgQSplNCHKD06Aq4kSTDXW1FtCzLVdZaGdVtwqbFtd6zbtot9RAtOTb24rabOipo6C8z1Vtt1i+N2+6hJVgmOUCS3IKWi2UB0axBSq5xvuzX02ANPsFKJ4CDFLbeJ24Ps1223O4enhm0MS9QRMZQQUYsUCoWj1SLSi88jSRJqLVbU1FlhbhRU7AHGXGeFuV5sN9fbt9ku6xuCjrneYtu3Yb86ixV19eLxa+3XLVbUWaSG2xtta6zeKqHe1oLkT4KUCkdQUQepoLYHnkYBKEilRJBSgSCVAkHKRuv27Uqxn8r2WCrb7cFKe6uSc4uS2tbSJLYpoFapnFuWbJdBtsdUKcRhOMe6ElDZrisUjdcZsEhgKCEiv6BQKGytDipAxrmO7OGoziKhtl6EmIYQJNZr651Dj7lxULolLNnDTr3F/rjisetsAane2rDe+LaGbeJ+t87EXW+VUG+1oLoOAOplea88SaVUQKkAlAqFLTzdEqhUCkeQcg5WDYHKHrCCVEqobI9jD1oq231VykbblQqolMpGt9+y/Zb72mtwCnGNalXZFmWjIKZUotF6o8vGtzOcOTCUEBE10hCOALS/m4/HWKy3h5U6i3PwqbWdml5nkVBXb0W9VYSeeotku7Q6Xzptc77eOCiJFiZbqHLaZnUELUdNtm1WSYLFKsHaxolMLFYJoi1KsvVW8q+WKV9QKuAINUFKEV6CGgWdxtvsAUfVKEg13l9lC1YqBRwBq6l9G9/niXEpSIrqIut7wFBCRBQAxA+KKiCnP7BaJRFSJAlWKxqti9Bisd1uDzIWR2AS4UhcF6HHHs7EpdjuWLdYUWcVj1tvlWCxhTKLxX79lu326/ZAZnss++NZGoU6i9X5uezXm7rd0uh12V+nRZJanHQUEH2prBYJDcHMtx4Y1p2hhIiIOjalUgElFJ3+B0eyhy5bQHEKLdaG2yyNrlulhkDltM1y+763PkbjfepvCWsWKxyhy749TqeV+y3q9J8RIiIin1AobH1k5C7Ej7k1POPbb7+Nnj17QqvVYvTo0Thw4ECL+69btw4DBgyAVqvFkCFD8MUXX7hVLBEREXVcLoeStWvXYuHChXjppZdw5MgRDBs2DBkZGSgtLW1y/71792LGjBmYPXs2jh49iszMTGRmZiIvL6/dxRMREVHHoZCk1rreOBs9ejRGjhyJt956CwBgtVqRlJSEn/3sZ3juuedu23/69OmorKzExo0bHdvGjBmD4cOHY+nSpW16TpPJBL1eD6PRCJ1O50q5REREJBNXf79daimpra3F4cOHkZ6e3vAASiXS09ORm5vb5H1yc3Od9geAjIyMZvcHALPZDJPJ5LQQERFRx+ZSKLl27RosFgtiY2OdtsfGxsJgMDR5H4PB4NL+AJCdnQ29Xu9YkpKSXCmTiIiIApBfzkOelZUFo9HoWIqKiuQuiYiIiLzMpTOToqOjoVKpUFJS4rS9pKQEcXFxTd4nLi7Opf0BQKPRQKPxo6EUiYiIyOtcailRq9VITU1FTk6OY5vVakVOTg7S0tKavE9aWprT/gCwbdu2ZvcnIiKizsnlMVwWLlyIWbNm4a677sKoUaPw5ptvorKyEo8//jgAYObMmUhISEB2djYA4Omnn8aECRPwxhtv4P7778eaNWtw6NAhLFu2zLOvhIiIiAKay6Fk+vTpuHr1Kl588UUYDAYMHz4cmzdvdnRmLSwshFLZ0AAzduxYrF69Gi+88AKef/559O3bFxs2bMDgwYM99yqIiIgo4Lk8TokcOE4JERFR4PHqOCVERERE3sJQQkRERH4hICYrtB9h4siuREREgcP+u93WniIBEUrKy8sBgCO7EhERBaDy8nLo9fpW9wuIjq5WqxVXrlxBeHg4FAqFxx7XZDIhKSkJRUVF7EDrAr5v7uH75jq+Z+7h++Yevm/uael9kyQJ5eXl6N69u9OZuc0JiJYSpVKJxMRErz2+TqfjB9ANfN/cw/fNdXzP3MP3zT1839zT3PvWlhYSO3Z0JSIiIr/AUEJERER+oVOHEo1Gg5deeomT/7mI75t7+L65ju+Ze/i+uYfvm3s8+b4FREdXIiIi6vg6dUsJERER+Q+GEiIiIvILDCVERETkFxhKiIiIyC906lDy9ttvo2fPntBqtRg9ejQOHDggd0l+7fe//z0UCoXTMmDAALnL8ju7d+/GAw88gO7du0OhUGDDhg1Ot0uShBdffBHx8fEICQlBeno6zp49K0+xfqK19+yxxx677bM3ZcoUeYr1E9nZ2Rg5ciTCw8MRExODzMxMnD592mmfmpoazJ8/H127dkVYWBi+973voaSkRKaK/UNb3reJEyfe9nmbN2+eTBX7hyVLlmDo0KGOAdLS0tKwadMmx+2e+qx12lCydu1aLFy4EC+99BKOHDmCYcOGISMjA6WlpXKX5tfuuOMOFBcXO5avv/5a7pL8TmVlJYYNG4a33367ydv/+Mc/4q9//SuWLl2K/fv3IzQ0FBkZGaipqfFxpf6jtfcMAKZMmeL02fvggw98WKH/2bVrF+bPn499+/Zh27ZtqKurw+TJk1FZWenY5xe/+AU+++wzrFu3Drt27cKVK1fw0EMPyVi1/NryvgHA3LlznT5vf/zjH2Wq2D8kJiZi0aJFOHz4MA4dOoR7770X06ZNw4kTJwB48LMmdVKjRo2S5s+f77husVik7t27S9nZ2TJW5d9eeukladiwYXKXEVAASOvXr3dct1qtUlxcnPT66687tpWVlUkajUb64IMPZKjQ/9z6nkmSJM2aNUuaNm2aLPUEitLSUgmAtGvXLkmSxOcqODhYWrdunWOfb7/9VgIg5ebmylWm37n1fZMkSZowYYL09NNPy1dUgIiMjJSWL1/u0c9ap2wpqa2txeHDh5Genu7YplQqkZ6ejtzcXBkr839nz55F9+7d0atXLzzyyCMoLCyUu6SAUlBQAIPB4PTZ0+v1GD16ND97rdi5cydiYmLQv39/PPXUU7h+/brcJfkVo9EIAIiKigIAHD58GHV1dU6ftQEDBiA5OZmftUZufd/s/v3vfyM6OhqDBw9GVlYWqqqq5CjPL1ksFqxZswaVlZVIS0vz6GctICbk87Rr167BYrEgNjbWaXtsbCxOnTolU1X+b/To0Vi5ciX69++P4uJivPzyy7j77ruRl5eH8PBwucsLCAaDAQCa/OzZb6PbTZkyBQ899BBSUlJw7tw5PP/885g6dSpyc3OhUqnkLk92VqsVzzzzDMaNG4fBgwcDEJ81tVqNiIgIp335WWvQ1PsGAD/60Y/Qo0cPdO/eHd988w1+85vf4PTp0/jkk09krFZ+x48fR1paGmpqahAWFob169dj0KBBOHbsmMc+a50ylJB7pk6d6lgfOnQoRo8ejR49euDDDz/E7NmzZayMOrqHH37YsT5kyBAMHToUvXv3xs6dOzFp0iQZK/MP8+fPR15eHvt4uai59+3JJ590rA8ZMgTx8fGYNGkSzp07h969e/u6TL/Rv39/HDt2DEajER999BFmzZqFXbt2efQ5OuXhm+joaKhUqtt6BpeUlCAuLk6mqgJPREQE+vXrh/z8fLlLCRj2zxc/e+3Tq1cvREdH87MHYMGCBdi4cSN27NiBxMREx/a4uDjU1tairKzMaX9+1oTm3remjB49GgA6/edNrVajT58+SE1NRXZ2NoYNG4bFixd79LPWKUOJWq1GamoqcnJyHNusVitycnKQlpYmY2WBpaKiAufOnUN8fLzcpQSMlJQUxMXFOX32TCYT9u/fz8+eCy5duoTr16936s+eJElYsGAB1q9fj+3btyMlJcXp9tTUVAQHBzt91k6fPo3CwsJO/Vlr7X1ryrFjxwCgU3/emmK1WmE2mz37WfNsX9zAsWbNGkmj0UgrV66UTp48KT355JNSRESEZDAY5C7Nbz377LPSzp07pYKCAmnPnj1Senq6FB0dLZWWlspdml8pLy+Xjh49Kh09elQCIP35z3+Wjh49Kl28eFGSJElatGiRFBERIX366afSN998I02bNk1KSUmRqqurZa5cPi29Z+Xl5dIvf/lLKTc3VyooKJC+/PJL6c4775T69u0r1dTUyF26bJ566ilJr9dLO3fulIqLix1LVVWVY5958+ZJycnJ0vbt26VDhw5JaWlpUlpamoxVy6+19y0/P1965ZVXpEOHDkkFBQXSp59+KvXq1UsaP368zJXL67nnnpN27dolFRQUSN9884303HPPSQqFQtq6daskSZ77rHXaUCJJkvS3v/1NSk5OltRqtTRq1Chp3759cpfk16ZPny7Fx8dLarVaSkhIkKZPny7l5+fLXZbf2bFjhwTgtmXWrFmSJInTgn/3u99JsbGxkkajkSZNmiSdPn1a3qJl1tJ7VlVVJU2ePFnq1q2bFBwcLPXo0UOaO3dup/8Doqn3C4D0j3/8w7FPdXW19NOf/lSKjIyUunTpIj344INScXGxfEX7gdbet8LCQmn8+PFSVFSUpNFopD59+ki/+tWvJKPRKG/hMnviiSekHj16SGq1WurWrZs0adIkRyCRJM991hSSJEluttwQEREReUyn7FNCRERE/oehhIiIiPwCQwkRERH5BYYSIiIi8gsMJUREROQXGEqIiIjILzCUEBERkV9gKCEiIiK/wFBCREREfoGhhIiIiPwCQwkRERH5BYYSIiIi8gv/H0BfOqAcl74kAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41555ccc-fe91-42e7-accb-f23ea81fe4c9",
   "metadata": {},
   "source": [
    "### 回帰NNのbackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082c4f04-de2a-45ce-b15d-26bd93c38259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y_train_reg = torch.argmax(y_train, dim=-1)\n",
    "\n",
    "def mse(X, y):\n",
    "    return (X[:, 0] - y).pow(2).mean()\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    # loss, A2 = softmax_cross_entropy(Z2, y) # -> MSE\n",
    "    loss = mse(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    # Z2.grad_ = (A2 - y) / X.shape[0] # -> MSE\n",
    "    Z2.grad_ = 2 * (Z2 - y.unsqueeze(dim=-1)) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2\n",
    "    \n",
    "# パラメータの初期化\n",
    "m, n = X_train.shape\n",
    "nh = 30\n",
    "# パラメータの初期化\n",
    "W1 = torch.randn((nh, n), requires_grad=True) # 出力 x 入力\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "W2 = torch.randn((1, nh), requires_grad=True) # 出力 x 入力\n",
    "b2 = torch.zeros((1, 1), requires_grad=True) # 1 x 1\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train_reg)\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab78ea9e-81bf-4297-be1f-bf930e2bcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reg = torch.argmax(y_train, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede6ca4-1d4b-4c87-aa55-26d6926c3704",
   "metadata": {},
   "source": [
    "### Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020f436a-7b3e-4d97-b3fd-b9c931e0f144",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: train error: 2.3414133116602898, validation error: 9.969054222106934, validation accuracy: 0.15555556118488312\n",
      "epoch: 1: train error: 1.9317669421434402, validation error: 8.740021705627441, validation accuracy: 0.19722221791744232\n",
      "epoch: 2: train error: 1.7252780000368755, validation error: 8.2929048538208, validation accuracy: 0.2361111044883728\n",
      "epoch: 3: train error: 1.558756907780965, validation error: 8.039956092834473, validation accuracy: 0.2666666805744171\n",
      "epoch: 4: train error: 1.4132022534807522, validation error: 7.559729099273682, validation accuracy: 0.28611111640930176\n",
      "epoch: 5: train error: 1.2803218724826972, validation error: 7.201395034790039, validation accuracy: 0.31388887763023376\n",
      "epoch: 6: train error: 1.1579220928251743, validation error: 6.90744686126709, validation accuracy: 0.3361110985279083\n",
      "epoch: 7: train error: 1.0501447257896264, validation error: 6.332675457000732, validation accuracy: 0.3638888895511627\n",
      "epoch: 8: train error: 0.9570859844485918, validation error: 5.526372909545898, validation accuracy: 0.39722222089767456\n",
      "epoch: 9: train error: 0.8725675816337267, validation error: 5.144354820251465, validation accuracy: 0.4277777671813965\n",
      "epoch: 10: train error: 0.7979398419459661, validation error: 4.552219867706299, validation accuracy: 0.47777777910232544\n",
      "epoch: 11: train error: 0.7298847176134586, validation error: 4.018589496612549, validation accuracy: 0.5333333611488342\n",
      "epoch: 12: train error: 0.6678423577298721, validation error: 3.641430377960205, validation accuracy: 0.5638889074325562\n",
      "epoch: 13: train error: 0.6110397018492222, validation error: 3.267422914505005, validation accuracy: 0.6111111044883728\n",
      "epoch: 14: train error: 0.5621715802699327, validation error: 2.857069492340088, validation accuracy: 0.6499999761581421\n",
      "epoch: 15: train error: 0.5183921083807945, validation error: 2.6363093852996826, validation accuracy: 0.6694444417953491\n",
      "epoch: 16: train error: 0.4803562785188357, validation error: 2.3997387886047363, validation accuracy: 0.7027778029441833\n",
      "epoch: 17: train error: 0.44623157009482384, validation error: 2.182451009750366, validation accuracy: 0.730555534362793\n",
      "epoch: 18: train error: 0.4172464019308488, validation error: 2.052581548690796, validation accuracy: 0.7444444298744202\n",
      "epoch: 19: train error: 0.3917269067217906, validation error: 1.9078150987625122, validation accuracy: 0.7666666507720947\n",
      "epoch: 20: train error: 0.37019176594913006, validation error: 1.708571195602417, validation accuracy: 0.7749999761581421\n",
      "epoch: 21: train error: 0.3504072626431783, validation error: 1.5471274852752686, validation accuracy: 0.7944444417953491\n",
      "epoch: 22: train error: 0.3343674074858427, validation error: 1.4464473724365234, validation accuracy: 0.8194444179534912\n",
      "epoch: 23: train error: 0.31856649182736874, validation error: 1.3583589792251587, validation accuracy: 0.824999988079071\n",
      "epoch: 24: train error: 0.3058976102620363, validation error: 1.3266228437423706, validation accuracy: 0.8444444537162781\n",
      "epoch: 25: train error: 0.2936727162450552, validation error: 1.2260762453079224, validation accuracy: 0.855555534362793\n",
      "epoch: 26: train error: 0.28162421720723313, validation error: 1.2021470069885254, validation accuracy: 0.8611111044883728\n",
      "epoch: 27: train error: 0.2725001769140363, validation error: 1.1021031141281128, validation accuracy: 0.875\n",
      "epoch: 28: train error: 0.26331881744166213, validation error: 1.0680567026138306, validation accuracy: 0.8777777552604675\n",
      "epoch: 29: train error: 0.2550269563992818, validation error: 1.0409376621246338, validation accuracy: 0.8777777552604675\n",
      "epoch: 30: train error: 0.24727943943192562, validation error: 0.9892693161964417, validation accuracy: 0.8777777552604675\n",
      "epoch: 31: train error: 0.24047297316913804, validation error: 0.9619333148002625, validation accuracy: 0.8916666507720947\n",
      "epoch: 32: train error: 0.23322040727362037, validation error: 0.9808387756347656, validation accuracy: 0.8916666507720947\n",
      "epoch: 33: train error: 0.22731250012293458, validation error: 0.9517503380775452, validation accuracy: 0.8888888955116272\n",
      "epoch: 34: train error: 0.22130623816822967, validation error: 0.8974583745002747, validation accuracy: 0.8916666507720947\n",
      "epoch: 35: train error: 0.2161262466882666, validation error: 0.8808713555335999, validation accuracy: 0.8916666507720947\n",
      "epoch: 36: train error: 0.2111391246629258, validation error: 0.8615171909332275, validation accuracy: 0.8999999761581421\n",
      "epoch: 37: train error: 0.20640936369697252, validation error: 0.8288798928260803, validation accuracy: 0.8999999761581421\n",
      "epoch: 38: train error: 0.20063634542748332, validation error: 0.8408821225166321, validation accuracy: 0.9027777910232544\n",
      "epoch: 39: train error: 0.1970865043501059, validation error: 0.8076257705688477, validation accuracy: 0.9083333611488342\n",
      "epoch: 40: train error: 0.19308520449946323, validation error: 0.7738549709320068, validation accuracy: 0.9083333611488342\n",
      "epoch: 41: train error: 0.1897620198627313, validation error: 0.759874701499939, validation accuracy: 0.9083333611488342\n",
      "epoch: 42: train error: 0.1850551045499742, validation error: 0.7774666547775269, validation accuracy: 0.9083333611488342\n",
      "epoch: 43: train error: 0.18241305137053132, validation error: 0.725590705871582, validation accuracy: 0.9166666865348816\n",
      "epoch: 44: train error: 0.17842856918772063, validation error: 0.757224977016449, validation accuracy: 0.9111111164093018\n",
      "epoch: 45: train error: 0.17565747164189816, validation error: 0.7093288898468018, validation accuracy: 0.9194444417953491\n",
      "epoch: 46: train error: 0.17273072991520166, validation error: 0.7198703289031982, validation accuracy: 0.9166666865348816\n",
      "epoch: 47: train error: 0.16935380101980022, validation error: 0.6781659722328186, validation accuracy: 0.9194444417953491\n",
      "epoch: 48: train error: 0.16653520101681352, validation error: 0.704483687877655, validation accuracy: 0.9166666865348816\n",
      "epoch: 49: train error: 0.16448990488424897, validation error: 0.6539093255996704, validation accuracy: 0.9194444417953491\n",
      "epoch: 50: train error: 0.1617532305729886, validation error: 0.6469234824180603, validation accuracy: 0.9222221970558167\n",
      "epoch: 51: train error: 0.15916278647879759, validation error: 0.6349105834960938, validation accuracy: 0.925000011920929\n",
      "epoch: 52: train error: 0.15753381606191397, validation error: 0.6360965967178345, validation accuracy: 0.925000011920929\n",
      "epoch: 53: train error: 0.15420812872859338, validation error: 0.6157649755477905, validation accuracy: 0.9305555820465088\n",
      "epoch: 54: train error: 0.15138082229532301, validation error: 0.6365750432014465, validation accuracy: 0.9277777671813965\n",
      "epoch: 55: train error: 0.14963203792770705, validation error: 0.6249232888221741, validation accuracy: 0.9305555820465088\n",
      "epoch: 56: train error: 0.14756676671095192, validation error: 0.6387903690338135, validation accuracy: 0.9333333373069763\n",
      "epoch: 57: train error: 0.1455026090455552, validation error: 0.6195639371871948, validation accuracy: 0.9333333373069763\n",
      "epoch: 58: train error: 0.14357986805650094, validation error: 0.6164141893386841, validation accuracy: 0.9305555820465088\n",
      "epoch: 59: train error: 0.14141477171021202, validation error: 0.6521419286727905, validation accuracy: 0.9305555820465088\n",
      "epoch: 60: train error: 0.13969540176913142, validation error: 0.6217498183250427, validation accuracy: 0.9277777671813965\n",
      "epoch: 61: train error: 0.13793033260541657, validation error: 0.605646014213562, validation accuracy: 0.9305555820465088\n",
      "epoch: 62: train error: 0.13600722576181093, validation error: 0.590661346912384, validation accuracy: 0.9361110925674438\n",
      "epoch: 63: train error: 0.13442028872668743, validation error: 0.6013012528419495, validation accuracy: 0.9333333373069763\n",
      "epoch: 64: train error: 0.1325842225148032, validation error: 0.5903618335723877, validation accuracy: 0.9333333373069763\n",
      "epoch: 65: train error: 0.13142587252271673, validation error: 0.5884485244750977, validation accuracy: 0.9305555820465088\n",
      "epoch: 66: train error: 0.12992124259471893, validation error: 0.6027292609214783, validation accuracy: 0.9277777671813965\n",
      "epoch: 67: train error: 0.12824893793246397, validation error: 0.5923973917961121, validation accuracy: 0.9305555820465088\n",
      "epoch: 68: train error: 0.12687167905581495, validation error: 0.6076616644859314, validation accuracy: 0.9222221970558167\n",
      "epoch: 69: train error: 0.1252125173341483, validation error: 0.5724537968635559, validation accuracy: 0.9277777671813965\n",
      "epoch: 70: train error: 0.12411753546136121, validation error: 0.5850123167037964, validation accuracy: 0.9277777671813965\n",
      "epoch: 71: train error: 0.12264969735406339, validation error: 0.6014457941055298, validation accuracy: 0.925000011920929\n",
      "epoch: 72: train error: 0.1208737079674999, validation error: 0.5901254415512085, validation accuracy: 0.9277777671813965\n",
      "epoch: 73: train error: 0.1201857109554112, validation error: 0.5950911641120911, validation accuracy: 0.9277777671813965\n",
      "epoch: 74: train error: 0.11838870216161013, validation error: 0.5909377932548523, validation accuracy: 0.9277777671813965\n",
      "epoch: 75: train error: 0.11735767669354875, validation error: 0.6235505938529968, validation accuracy: 0.9222221970558167\n",
      "epoch: 76: train error: 0.11618326736303668, validation error: 0.5824452638626099, validation accuracy: 0.925000011920929\n",
      "epoch: 77: train error: 0.11479892539015661, validation error: 0.5858514904975891, validation accuracy: 0.925000011920929\n",
      "epoch: 78: train error: 0.11359859102716048, validation error: 0.6336230039596558, validation accuracy: 0.9194444417953491\n",
      "epoch: 79: train error: 0.1123534197298189, validation error: 0.6175284385681152, validation accuracy: 0.925000011920929\n",
      "epoch: 80: train error: 0.1110205293322603, validation error: 0.6187830567359924, validation accuracy: 0.9222221970558167\n",
      "epoch: 81: train error: 0.11027842985155682, validation error: 0.6091366410255432, validation accuracy: 0.925000011920929\n",
      "epoch: 82: train error: 0.10874743359939505, validation error: 0.5830639004707336, validation accuracy: 0.9277777671813965\n",
      "epoch: 83: train error: 0.10812679414326946, validation error: 0.6105395555496216, validation accuracy: 0.9194444417953491\n",
      "epoch: 84: train error: 0.10672536011164387, validation error: 0.6031164526939392, validation accuracy: 0.9222221970558167\n",
      "epoch: 85: train error: 0.10593907255679369, validation error: 0.6385689377784729, validation accuracy: 0.9222221970558167\n",
      "epoch: 86: train error: 0.10496385605074465, validation error: 0.6306825280189514, validation accuracy: 0.9166666865348816\n",
      "epoch: 87: train error: 0.10368720069527626, validation error: 0.6110055446624756, validation accuracy: 0.9222221970558167\n",
      "epoch: 88: train error: 0.103028419543989, validation error: 0.6237397789955139, validation accuracy: 0.9166666865348816\n",
      "epoch: 89: train error: 0.10181006762043883, validation error: 0.6100364327430725, validation accuracy: 0.925000011920929\n",
      "epoch: 90: train error: 0.10087127238512039, validation error: 0.6251258254051208, validation accuracy: 0.9222221970558167\n",
      "epoch: 91: train error: 0.09994792773310716, validation error: 0.6164356470108032, validation accuracy: 0.9194444417953491\n",
      "epoch: 92: train error: 0.09907185550158222, validation error: 0.626299262046814, validation accuracy: 0.9166666865348816\n",
      "epoch: 93: train error: 0.09820401175723721, validation error: 0.6527766585350037, validation accuracy: 0.9194444417953491\n",
      "epoch: 94: train error: 0.09727156344645967, validation error: 0.630585253238678, validation accuracy: 0.9194444417953491\n",
      "epoch: 95: train error: 0.0963528569166859, validation error: 0.6220009922981262, validation accuracy: 0.9194444417953491\n",
      "epoch: 96: train error: 0.09582187080134948, validation error: 0.6127387881278992, validation accuracy: 0.9222221970558167\n",
      "epoch: 97: train error: 0.0951667654638489, validation error: 0.6586142182350159, validation accuracy: 0.9194444417953491\n",
      "epoch: 98: train error: 0.09358512986606608, validation error: 0.638701856136322, validation accuracy: 0.9222221970558167\n",
      "epoch: 99: train error: 0.0933237827460592, validation error: 0.6503159999847412, validation accuracy: 0.9194444417953491\n"
     ]
    }
   ],
   "source": [
    "# ======モデル======\n",
    "class Linear():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = torch.randn((out_features, in_features)) * torch.sqrt(torch.tensor(2.0 / in_features))\n",
    "        self.W.requires_grad = True\n",
    "        self.b = torch.zeros((1, out_features), requires_grad=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.Z = X @ self.W.T + self.b\n",
    "        return self.Z\n",
    "\n",
    "    def backward(self, Z):\n",
    "        self.W.grad_ = Z.grad_.T @ self.X\n",
    "        self.b.grad_ = torch.sum(Z.grad_, dim=0)\n",
    "        self.X.grad_ = Z.grad_ @ self.W\n",
    "        return self.X.grad_\n",
    "\n",
    "class ReLU():\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return X.clamp_min(0.)\n",
    "\n",
    "    def backward(self, A):\n",
    "        return A.grad_ * (self.X > 0).float()\n",
    "\n",
    "class SoftmaxCrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        e_x = torch.exp(X - torch.max(X, dim=-1, keepdim=True)[0])\n",
    "        self.softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)    \n",
    "        \n",
    "        log_probs = torch.log(self.softmax_out + 1e-10)\n",
    "        target_log_probs = log_probs * y\n",
    "\n",
    "        self.loss = -target_log_probs.sum(dim=-1).mean()\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, y):\n",
    "        return (self.softmax_out - y) / y.shape[0]\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_features, hidden_units, output_units):\n",
    "        self.linear1 = Linear(input_features, hidden_units)\n",
    "        self.relu = ReLU()\n",
    "        self.linear2 = Linear(hidden_units, output_units)\n",
    "        self.loss_fn = SoftmaxCrossEntropy()\n",
    "        \n",
    "    def forward(self, X, y):\n",
    "        self.X = X\n",
    "        self.Z1 = self.linear1.forward(X)\n",
    "        self.A1 = self.relu.forward(self.Z1)\n",
    "        self.Z2 = self.linear2.forward(self.A1)\n",
    "        self.loss = self.loss_fn.forward(self.Z2, y)\n",
    "        return self.loss, self.Z2\n",
    "    \n",
    "    def backward(self, y):\n",
    "        self.Z2.grad_ = self.loss_fn.backward(y)\n",
    "        self.A1.grad_ = self.linear2.backward(self.Z2)\n",
    "        self.Z1.grad_ = self.relu.backward(self.A1)\n",
    "        self.X.grad_ = self.linear1.backward(self.Z1)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        # 勾配の初期化\n",
    "        self.linear1.W.grad_ = None\n",
    "        self.linear1.b.grad_ = None\n",
    "        self.linear2.W.grad_ = None\n",
    "        self.linear2.b.grad_ = None\n",
    "        \n",
    "    def step(self, learning_rate):\n",
    "        # パラメータの更新\n",
    "        self.linear1.W -= learning_rate * self.linear1.W.grad_\n",
    "        self.linear1.b -= learning_rate * self.linear1.b.grad_\n",
    "        self.linear2.W -= learning_rate * self.linear2.W.grad_\n",
    "        self.linear2.b -= learning_rate * self.linear2.b.grad_\n",
    "\n",
    "## Refactoring後の学習ループ(OptimizerやDataset, Dataloaderは後ほどRefactoring)\n",
    "# ===データの準備====\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_val = (X_val - X_train.mean()) / X_train.std()\n",
    "X_train = torch.tensor(X_train.reshape(-1, 64), dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.reshape(-1, 64), dtype=torch.float32)\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10) #1437 x 10 \n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10) # 360 x 10\n",
    "batch_size = 30\n",
    "# モデルの初期化\n",
    "model = Model(input_features=64, hidden_units=10, output_units=10)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in range(100):\n",
    "    # エポック毎にデータをシャッフル\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    num_batches = np.ceil(len(y_train)/batch_size).astype(int)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        \n",
    "        # mini batch作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        y_true_ = y_train[batch_indices, :] # batch_size x 10\n",
    "        \n",
    "        X = X_train[batch_indices] # batch_size x 64\n",
    "        # 順伝播と逆伝播の計算\n",
    "        loss, _ = model.forward(X, y_true_)\n",
    "        model.backward(y_true_)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            model.step(learning_rate)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        val_loss, Z2_val = model.forward(X_val, y_val)\n",
    "        \n",
    "        val_accuracy = torch.sum(torch.argmax(Z2_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f'epoch: {epoch}: train error: {running_loss/num_batches}, validation error: {val_loss.item()}, validation accuracy: {val_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
